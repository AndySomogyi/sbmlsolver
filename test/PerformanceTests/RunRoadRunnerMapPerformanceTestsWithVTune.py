"""Run VTune profiler systematically using command line

Make sure to use the debug build.

Example
--------
python .\RunRoadRunnerMapPerformanceTestsWithVTune.py --VTune "C:\Program Files (x86)\Intel\oneAPI\vtune\latest\bin64\vtune.exe" --RoadRunnerMapPerformanceTestsExecutable D:\roadrunner\roadrunner\cmake-build-debug\bin\RoadRunnerMapPerformanceTests.exe --OutputDirectory D:\roadrunner\Profiler\RoadRunnerProfiling
"""

import glob, os, argparse
import sys
import subprocess
from typing import *

parser = argparse.ArgumentParser()
parser.add_argument("--VTune", type=str, help="Absolute path to the VTune executable", nargs="+")
parser.add_argument("--RoadRunnerMapPerformanceTestsExecutable", type=str, nargs="+",
                    help="Absolute path to location of the RoadRunnerMapPerformanceTestsExecutable")
parser.add_argument("--OutputDirectory", type=str, help="Absolute path to the directory for storing data", nargs="+")

group = parser.add_mutually_exclusive_group()
group.add_argument('--threading', action='store_true')
group.add_argument('--hotspots', action='store_true')

args = parser.parse_args()

vtuneExe = args.VTune if isinstance(args.VTune, str) else "".join(args.VTune)
perfExe = args.VTune if isinstance(args.RoadRunnerMapPerformanceTestsExecutable, str) else "".join(
    args.RoadRunnerMapPerformanceTestsExecutable)
outDir = args.VTune if isinstance(args.OutputDirectory, str) else "".join(args.OutputDirectory)

hotspots = None
if args.hotspots:
    hotspots = args.hotspots
threading = None
if args.threading:
    threading = args.threading


def run_vtune_command_loop(command: callable, n_models: List[int], jit_engines: List[str], threads: List[int], label: str, **kwargs):
    """Run the parallel loop with command generated by the callable command.

    End result is length len(n_models) * len(jit_engines) * len(threads)

    Args:
        command: buildThreadingAnalysisCommand or buildHotSpotsAnalysisCommand. Or more generally
                 a function with the signature f(num_models=int, jit_engine=str, num_threads=int, run_label=str) -> str.
                 The return value is a string representing a VTune command
        n_models: List of int, how many models to run.
        jit_engines: List of jit engines to use. Options are MCJit and LLJit.
        threads: List of how many threads to use.

    Returns: None

    """
    # and now the parallel tests
    for n in n_models:
        for j in jit_engines:
            for t in threads:
                print("Running BuildParallel", "n models: ", n, " jit type: ", j, "num threads: ", t)
                dire = build_results_dirname(n, j, t, label)

                # when running analysis, we skip over directories that already exist.
                # but when generating reports, skip nothing.
                if kwargs.get("report_type"):
                    cmd = command(n_models=n, jit=j, n_threads=t, label=label, **kwargs)
                    subprocess.check_call(cmd, shell=True)
                elif not kwargs.get("report_type") and not os.path.isdir(dire):
                    print("Running BuildParallel ", n, j, t)
                    cmd = command(n_models=n, jit=j, n_threads=t, label=label, **kwargs)
                    print(cmd)
                    subprocess.check_call(cmd, shell=True)


def build_results_dirname(n_models: int, jit: str, n_threads: int, label: str):
    return os.path.join(outDir, f"{jit}_{n_models}_{n_threads}_{label}")


def buildThreadingAnalysisCommand(n_models: int, jit: str, n_threads: int, label: str):
    dirname = build_results_dirname(n_models, jit, n_threads, label)
    command = f"\"{vtuneExe}\" -collect threading -knob sampling-and-waits=hw -knob sampling-interval=10 "
    command += f"-app-working-dir \"{outDir}\" --app-working-dir=\"{outDir}\" -no-allow-multiple-runs -result-dir=\"{dirname}\" --data-limit=6000 "
    command += f" -- {perfExe} "
    command += f"--NModels={n_models} --jit={jit} --nThreads={n_threads} --testName={label}"
    return command


def buildHotSpotsAnalysisCommand(n_models: int, jit: str, n_threads: int, label: str):
    dirname = build_results_dirname(n_models, jit, n_threads, label)
    command = f"\"{vtuneExe}\" --collect hotspots "
    command += f"-app-working-dir \"{outDir}\" --app-working-dir=\"{outDir}\" -no-allow-multiple-runs -result-dir=\"{dirname}\" --data-limit=6000 "
    command += f" -- {perfExe} "
    command += f"--NModels={n_models} --jit={jit} --nThreads={n_threads} --testName={label}"
    return command


def buildReportCommand(report_type: str, n_models: int, jit: str, n_threads: int, label: str):
    """

    Example command:
        vtune --report summary -r D:\roadrunner\Profiler\RoadRunnerMapProfiling\LLJit_100_1_BuildParallel/LLJit_100_1_BuildParallel.vtune --report-output D:\roadrunner\Profiler\RoadRunnerMapProfiling\LLJit_100_1_BuildParallel/LLJit_100_1_BuildParallel_Summary.txt
    Args:
        report_type:
        n_models:
        jit:
        n_threads:
        label:

    Returns:

    """
    dirname = build_results_dirname(n_models, jit, n_threads, label)
    run_name = os.path.split(dirname)[1]
    vtune_result_file = os.path.join(dirname, run_name + ".vtune")
    report_type_label = report_type[0].upper() + report_type[1:]
    report_name = os.path.join(dirname, run_name + f"_{report_type_label}.csv")
    command = f"\"{vtuneExe}\" --report {report_type} -r {vtune_result_file} --report-output {report_name} --format=csv --csv-delimiter=comma"
    return command


if __name__ == "__main__":
    n_models = [100]
    jit_engines = ["MCJit", "LLJit"]
    # testNames = ["BuildParallel", "BuildSerial"]
    threads = [i for i in range(1, 16)]
    if not os.path.isdir(outDir):
        os.makedirs(outDir)

    if hotspots:
        print("Running hotspots analysis")
        run_vtune_command_loop(
            buildHotSpotsAnalysisCommand,
            n_models=n_models,
            jit_engines=jit_engines,
            threads=threads,
            label="BuildParallel"
        )
        print("Collecting results for hotspots analysis")
        run_vtune_command_loop(
            buildReportCommand,
            report_type="summary",
            n_models=n_models,
            jit_engines=jit_engines,
            threads=threads,
            label="BuildParallel"
        )
    if threading:
        print("Running threading analysis")
        run_vtune_command_loop(
            buildThreadingAnalysisCommand,
            n_models=n_models,
            jit_engines=jit_engines,
            threads=threads,
            label="BuildParallel"
        )
        print("Collecting results for threading analysis")
        run_vtune_command_loop(
            buildReportCommand,
            report_type="summary",
            n_models=n_models,
            jit_engines=jit_engines,
            threads=threads,
            label="BuildParallel"
        )

"""
Old code: 

    # # first run the serial tests, since we do not run these with different number of threads
    # if not report:
    #     for n in n_models:
    #         for j in jit_engines:
    #             print("Running BuildSerial ", "n models: ", n, " jit type: ", j)
    #             dire = build_results_dirname(n, j, 1, "BuildSerial")
    #             if not os.path.isdir(dire):
    #                 # cmd = buildThreadingAnalysisCommand(n, j, 1, "BuildSerial")
    #                 cmd = buildHotSpotsAnalysisCommand(n, j, 1, "BuildSerial")
    #                 print(cmd)
    #                 subprocess.check_output(cmd, shell=True)
    
"""
